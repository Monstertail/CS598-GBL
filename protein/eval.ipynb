{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protrein generative models evaluation metrics\n",
    "## Environment Preparation\n",
    "### Conda Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set up the conda environment by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda env create -f eval.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides, you have to install the following packages:\n",
    "\n",
    "``` bash\n",
    "\n",
    "pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
    "pip install fair-esm\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foldseek database\n",
    "\n",
    "When we calculate the novelty metric, we use the Foldseek database.\n",
    "\n",
    "\n",
    "``` bash\n",
    "\n",
    "conda install -c conda-forge -c bioconda foldseek\n",
    "mkdir ./foldseek_database\n",
    "cd ./foldseek_database\n",
    "foldseek databases PDB pdb tmp \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foldseek will download the PDB database automatically. After the download, you directory should look like this:\n",
    "\n",
    "```\n",
    "foldseek_database\n",
    "    ├── pdb\n",
    "    ├── pdb_ca\n",
    "    ├── pdb_ca.dbtype\n",
    "    ├── pdb_ca.index\n",
    "    ├── pdb_clu\n",
    "    ├── pdb_clu.dbtype\n",
    "    ├── pdb_clu.index\n",
    "    ├── pdb.dbtype\n",
    "    ├── pdb_h\n",
    "    ├── pdb_h.dbtype\n",
    "    ├── pdb_h.index\n",
    "    ├── pdb.index\n",
    "    ├── pdb.lookup\n",
    "    ├── pdb_mapping\n",
    "    ├── pdb_seq.0 -> pdb\n",
    "    ├── pdb_seq.1\n",
    "    ...\n",
    "```\n",
    "\n",
    "After downloading the foldseek database, you need to replace the database path in the `foldseek_database` field of the `configs/evaluation.yaml` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maxcluster\n",
    "\n",
    "When we cluster the designed protein based on their structure, we use maxcluster to cluster them.\n",
    "\n",
    "``` bash\n",
    "wget https://www.sbg.bio.ic.ac.uk/maxcluster/maxcluster64bit\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example data\n",
    "\n",
    "We provide some example data `./example_data` for testing purposes.\n",
    "\n",
    "```\n",
    "└── length_70\n",
    "    ├── sample_0\n",
    "    │   ├── bb_traj.pdb\n",
    "    │   ├── sample.pdb\n",
    "    │   └── x0_traj.pdb\n",
    "    ├── sample_1\n",
    "    │   ├── bb_traj.pdb\n",
    "    │   ├── sample.pdb\n",
    "    │   └── x0_traj.pdb\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProteinMPNN\n",
    "\n",
    "We can use the ProteinMPNN model to design a sequence for a given structure. \n",
    "\n",
    "``` bash\n",
    "\n",
    "git clone https://github.com/dauparas/ProteinMPNN.git\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Single pdb evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import hydra\n",
    "import torch\n",
    "import subprocess\n",
    "import logging\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from biotite.sequence.io import fasta\n",
    "import GPUtil\n",
    "from typing import Optional, Union, List\n",
    "from analysis import utils as au\n",
    "from analysis import metrics\n",
    "from data import utils as du\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from openfold.data import data_transforms\n",
    "import esm\n",
    "from pathlib import Path\n",
    "import mdtraj as md\n",
    "from openfold.np import residue_constants\n",
    "from tmtools import tm_align\n",
    "from openfold.utils.superimposition import superimpose\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictToObject:\n",
    "    def __init__(self, dictionary):\n",
    "        for key, value in dictionary.items():\n",
    "            if isinstance(value, dict):\n",
    "                setattr(self, key, DictToObject(value))\n",
    "            else:\n",
    "                setattr(self, key, value)\n",
    "\n",
    "def load_config(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 5.79 GiB total capacity; 5.32 GiB already allocated; 12.19 MiB free; 5.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m config_dict \u001b[38;5;241m=\u001b[39m load_config(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./configs/evaluation.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m conf \u001b[38;5;241m=\u001b[39m DictToObject(config_dict)\n\u001b[0;32m----> 4\u001b[0m EvalModel \u001b[38;5;241m=\u001b[39m \u001b[43mEvalRunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Project/protein-evaluation-notebook/EvalRunner.py:62\u001b[0m, in \u001b[0;36mEvalRunner.__init__\u001b[0;34m(self, conf)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Load ESMFold model\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_folding_model \u001b[38;5;241m=\u001b[39m esm\u001b[38;5;241m.\u001b[39mpretrained\u001b[38;5;241m.\u001b[39mesmfold_v1()\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_folding_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_folding_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 797 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 5.79 GiB total capacity; 5.32 GiB already allocated; 12.19 MiB free; 5.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from EvalRunner import EvalRunner\n",
    "config_dict = load_config(\"./configs/evaluation.yaml\")\n",
    "conf = DictToObject(config_dict)\n",
    "EvalModel = EvalRunner(conf)\n",
    "\n",
    "# Warning: ESMFold and ProteinMPNN pipeline need more than 12G GPU memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self consistency metrics\n",
    "\n",
    "```mermaid\n",
    "\n",
    "graph TD;\n",
    "    A[Protein Generative models] --> B[ProteinMPNN (inverse folding)];\n",
    "    B --> C[ESMFold (folding)];\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tm_score</th>\n",
       "      <th>bb_rmsd</th>\n",
       "      <th>sample_path</th>\n",
       "      <th>header</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.285942</td>\n",
       "      <td>12.353213</td>\n",
       "      <td>/home/shuaikes/server2/shuaikes/projects/prote...</td>\n",
       "      <td>sample, score=2.0021, global_score=2.0021, fix...</td>\n",
       "      <td>AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.820439</td>\n",
       "      <td>2.127891</td>\n",
       "      <td>/home/shuaikes/server2/shuaikes/projects/prote...</td>\n",
       "      <td>T=0.1, sample=1, score=1.0243, global_score=1....</td>\n",
       "      <td>ATLTKMLVKVKDKSITLEDVKKIIKEVGVDAEIEIDKETNTVTITA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.838250</td>\n",
       "      <td>2.160685</td>\n",
       "      <td>/home/shuaikes/server2/shuaikes/projects/prote...</td>\n",
       "      <td>T=0.1, sample=2, score=1.0038, global_score=1....</td>\n",
       "      <td>SILTKLKIKIKDKSINLEDIKKIAKEEGINCKIEIDKETNEVIVEA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.852542</td>\n",
       "      <td>1.917273</td>\n",
       "      <td>/home/shuaikes/server2/shuaikes/projects/prote...</td>\n",
       "      <td>T=0.1, sample=3, score=0.9787, global_score=0....</td>\n",
       "      <td>MVKTKMKIKIKDKSINKEDIEKIVKEEGLNVEIEIDKDTNTVTVKG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tm_score    bb_rmsd                                        sample_path  \\\n",
       "0  0.285942  12.353213  /home/shuaikes/server2/shuaikes/projects/prote...   \n",
       "1  0.820439   2.127891  /home/shuaikes/server2/shuaikes/projects/prote...   \n",
       "2  0.838250   2.160685  /home/shuaikes/server2/shuaikes/projects/prote...   \n",
       "3  0.852542   1.917273  /home/shuaikes/server2/shuaikes/projects/prote...   \n",
       "\n",
       "                                              header  \\\n",
       "0  sample, score=2.0021, global_score=2.0021, fix...   \n",
       "1  T=0.1, sample=1, score=1.0243, global_score=1....   \n",
       "2  T=0.1, sample=2, score=1.0038, global_score=1....   \n",
       "3  T=0.1, sample=3, score=0.9787, global_score=0....   \n",
       "\n",
       "                                            sequence  \n",
       "0  AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA...  \n",
       "1  ATLTKMLVKVKDKSITLEDVKKIIKEVGVDAEIEIDKETNTVTITA...  \n",
       "2  SILTKLKIKIKDKSINLEDIKKIAKEEGINCKIEIDKETNEVIVEA...  \n",
       "3  MVKTKMKIKIKDKSINKEDIEKIVKEEGLNVEIEIDKDTNTVTVKG...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example pdb path\n",
    "pdb_path = \"/home/shuaikes/server2/shuaikes/projects/protein-evaluation-notebook/example_data/length_70/sample_0/\"\n",
    "sc_output_dir = os.path.join(pdb_path, \"self_consistency\")\n",
    "os.makedirs(sc_output_dir, exist_ok=True)\n",
    "\n",
    "sc_results = EvalModel.calc_designability(sc_output_dir, pdb_path)\n",
    "sc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub-structure ratio evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'non_coil_percent': 0.6571428571428571,\n",
       " 'coil_percent': 0.34285714285714286,\n",
       " 'helix_percent': 0.34285714285714286,\n",
       " 'strand_percent': 0.3142857142857143,\n",
       " 'radius_of_gyration': 1.0974538862859071}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(pdb_path, \"sample.pdb\")\n",
    "sub_ratio = EvalModel.calc_mdtraj_metrics(path)\n",
    "sub_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Novelty: pdbTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TM-Score between sample.pdb and its closest protein in PDB is 0.867.\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(pdb_path, \"sample.pdb\")\n",
    "value = EvalModel.pdbTM(pdb_path)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Maybe you will encounter some issues here because of the different versions of the packages and foldseek path. So we provide a shell script to help you to run the foldseek to calculate the pdbTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foldseek enables fast and sensitive comparisons of large structure sets. It reaches sensitivities similar to state-of-the-art structural aligners while being at least 20,000 times faster.\n",
      "\n",
      "Please cite:\n",
      "van Kempen, M., Kim, S.S., Tumescheit, C., Mirdita, M., Lee, J., Gilchrist, C.L.M., Söding, J., and Steinegger, M. Fast and accurate protein structure search with Foldseek. Nature Biotechnology, doi:10.1038/s41587-023-01773-0 (2023)\n",
      "\n",
      "foldseek Version: 9.427df8a\n",
      "© Michel van Kempen, Stephanie Kim, Charlotte Tumescheit, Milot Mirdita, Jeongjae Lee, Cameron L. M. Gilchrist, Johannes Söding, Martin Steinegger\n",
      "\n",
      "usage: foldseek <command> [<args>]\n",
      "\n",
      "Easy workflows for plain text input/output\n",
      "  easy-search       \tStructual search\n",
      "  easy-cluster      \tSlower, sensitive clustering\n",
      "  easy-rbh          \tFind reciprocal best hit\n",
      "  easy-multimersearch\tComplex level search\n",
      "  easy-complexsearch\t\n",
      "\n",
      "Main workflows for database input/output\n",
      "  createdb          \tConvert PDB/mmCIF/tar[.gz]/DB files or directory/TSV to a structure DB\n",
      "  search            \tSensitive homology search\n",
      "  rbh               \tReciprocal best hit search\n",
      "  cluster           \tSlower, sensitive clustering\n",
      "  multimersearch    \tComplex level search\n",
      "\n",
      "Input database creation\n",
      "  databases         \tList and download databases\n",
      "  createindex       \tStore precomputed index on disk to reduce search overhead\n",
      "  createclusearchdb \tBuild a searchable cluster database allowing for faster searches\n",
      "\n",
      "Format conversion for downstream processing\n",
      "  convertalis       \tConvert alignment DB to BLAST-tab, SAM or custom format\n",
      "  compressca        \tCreate a new C-alpha DB with chosen compression encoding from a sequence DB\n",
      "  convert2pdb       \tConvert a foldseek structure db to a single multi model PDB file or a directory of PDB files\n",
      "  createmultimerreport\tConvert complexDB to tsv format\n",
      "  createcomplexreport\t\n",
      "\n",
      "Prefiltering        \n",
      "  expandmultimer    \tRe-prefilter to ensure complete alignment between complexes\n",
      "  expandcomplex     \t\n",
      "\n",
      "Alignment           \n",
      "  tmalign           \tCompute tm-score \n",
      "  structurealign    \tCompute structural alignment using 3Di alphabet, amino acids and neighborhood information\n",
      "  structurerescorediagonal\tCompute sequence identity for diagonal\n",
      "  aln2tmscore       \tCompute tmscore of an alignment database \n",
      "  scoremultimer     \tGet complex level alignments from alignmentDB\n",
      "\n",
      "Clustering          \n",
      "  clust             \tCluster result by Set-Cover/Connected-Component/Greedy-Incremental\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!foldseek -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Foldseek...\n",
      "rmdb ./tmp//7846871783882344137/search_tmp/8537189719342743872/pref_tmp_1 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "mergedbs ./tmp//7846871783882344137/search_tmp/8537189719342743872/profile_0 ./tmp//7846871783882344137/result ./tmp//7846871783882344137/search_tmp/8537189719342743872/aln_0 ./tmp//7846871783882344137/search_tmp/8537189719342743872/aln_tmp_1 \n",
      "\n",
      "Merging the results to ./tmp//7846871783882344137/result\n",
      "[=================================================================] 100.00% 1 eta -\n",
      "Time for merging to result: 0h 0m 0s 0ms\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb ./tmp//7846871783882344137/search_tmp/8537189719342743872/aln_0 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb ./tmp//7846871783882344137/search_tmp/8537189719342743872/aln_tmp_1 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "# variables\n",
    "input=\"/home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_0/sample.pdb\"\n",
    "foldseek_database_path=\"/home/shuaikes/Project/protein-evaluation-notebook/foldseek_database/pdb\"\n",
    "output_file=\"/home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_0/sample_pdb.m8\"\n",
    "tmp_path=\"./tmp/\"\n",
    "# replace with your actual input file path and output file path\n",
    "\n",
    "\n",
    "# set up directory\n",
    "!echo \"Running Foldseek...\"\n",
    "!mkdir -p $tmp_path\n",
    "\n",
    "\n",
    "# run the command\n",
    "!foldseek easy-search \\\n",
    "    $input \\\n",
    "    $foldseek_database_path \\\n",
    "    $output_file \\\n",
    "    $tmp_path \\\n",
    "    --format-mode 4 \\\n",
    "    --format-output query,target,evalue,alntmscore,rmsd,prob \\\n",
    "    --alignment-type 1 \\\n",
    "    --num-iterations 2 \\\n",
    "    -e inf \\\n",
    "    -v 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.867"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace with your own output file\n",
    "output_file = \"/home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_0/sample_pdb.m8\"\n",
    "result = pd.read_csv(output_file, sep=\"\\t\")\n",
    "top_pdbTM = round(result[\"alntmscore\"].head(1).max(), 3)\n",
    "top_pdbTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate all metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating all metrics...\n",
      "##########################################################################\n",
      "Calculating designability...\n",
      "   tm_score    bb_rmsd                                        sample_path  \\\n",
      "0  0.285942  12.353213  /home/shuaikes/server2/shuaikes/projects/prote...   \n",
      "1  0.820439   2.127891  /home/shuaikes/server2/shuaikes/projects/prote...   \n",
      "2  0.838250   2.160685  /home/shuaikes/server2/shuaikes/projects/prote...   \n",
      "3  0.852542   1.917273  /home/shuaikes/server2/shuaikes/projects/prote...   \n",
      "\n",
      "                                              header  \\\n",
      "0  sample, score=2.0021, global_score=2.0021, fix...   \n",
      "1  T=0.1, sample=1, score=1.0243, global_score=1....   \n",
      "2  T=0.1, sample=2, score=1.0038, global_score=1....   \n",
      "3  T=0.1, sample=3, score=0.9787, global_score=0....   \n",
      "\n",
      "                                            sequence  \n",
      "0  AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA...  \n",
      "1  ATLTKMLVKVKDKSITLEDVKKIIKEVGVDAEIEIDKETNTVTITA...  \n",
      "2  SILTKLKIKIKDKSINLEDIKKIAKEEGINCKIEIDKETNEVIVEA...  \n",
      "3  MVKTKMKIKIKDKSINKEDIEKIVKEEGLNVEIEIDKDTNTVTVKG...  \n",
      "##########################################################################\n",
      "Calculating substructure ratio...\n",
      "   non_coil_percent  coil_percent  helix_percent  strand_percent  \\\n",
      "0          0.657143      0.342857       0.342857        0.314286   \n",
      "\n",
      "   radius_of_gyration  \n",
      "0            1.097454  \n",
      "##########################################################################\n",
      "Calculating novelty (pdbTM)...\n",
      "TM-Score between sample.pdb and its closest protein in PDB is 0.867.\n",
      "##########################################################################\n"
     ]
    }
   ],
   "source": [
    "EvalModel.calc_all_metrics(sc_output_dir, pdb_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diversity: number of clusters\n",
    "\n",
    "We are not able to calculate the diversity of the cluster for just single protein strucuture. So we need multiple pdb files here and we use csv to specify the path the protein structures.\n",
    "\n",
    "Your csv file should like this:\n",
    "\n",
    "```\n",
    "/home/shuaikes/server2/shuaikes/projects/protein-evaluation-notebook/example_data/length_70/sample_0/\n",
    "/home/shuaikes/server2/shuaikes/projects/protein-evaluation-notebook/example_data/length_70/sample_1/\n",
    "/home/shuaikes/server2/shuaikes/projects/protein-evaluation-notebook/example_data/length_70/sample_2/\n",
    "/home/shuaikes/server2/shuaikes/projects/protein-evaluation-notebook/example_data/length_70/sample_3/\n",
    "/home/shuaikes/server2/shuaikes/projects/protein-evaluation-notebook/example_data/length_70/sample_4/\n",
    "/home/shuaikes/server2/shuaikes/projects/protein-evaluation-notebook/example_data/length_70/sample_5/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdb_csv_path = \"/home/shuaikes/server2/shuaikes/projects/protein-evaluation-notebook/pdb_path.csv\"\n",
    "clusters = EvalModel.calc_diversity(pdb_csv_path)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Also, you may encounter similar issues with other libraries or tools. So we provide some scripts to run the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "designable_file_path:  /home/shuaikes/Project/protein-evaluation-notebook/cluster/designable_paths.txt\n",
      "cluster_dir:  /home/shuaikes/Project/protein-evaluation-notebook/cluster\n"
     ]
    }
   ],
   "source": [
    "# set up workspace\n",
    "\n",
    "pdb_csv_path = \"/home/shuaikes/Project/protein-evaluation-notebook/pdb_path.csv\"\n",
    "df = pd.read_csv(pdb_csv_path, header=None)\n",
    "pdb_path_list = df[0].tolist()\n",
    "\n",
    "cluster_dir = os.path.join(Path(pdb_csv_path).parent, \"cluster\")\n",
    "os.makedirs(cluster_dir, exist_ok=True)\n",
    "designable_paths = pdb_path_list\n",
    "designable_file_path = os.path.join(cluster_dir, \"designable_paths.txt\")\n",
    "updated_paths = [os.path.join(path, \"sample.pdb\") for path in designable_paths]\n",
    "with open(designable_file_path, \"w\") as f:\n",
    "    f.write(\"\\n\".join(updated_paths))\n",
    "    \n",
    "print(\"designable_file_path: \", designable_file_path)\n",
    "print(\"cluster_dir: \", cluster_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "designable_file_path = \"/home/shuaikes/Project/protein-evaluation-notebook/cluster/designable_paths.txt\"\n",
    "cluster_dir = \"/home/shuaikes/Project/protein-evaluation-notebook/cluster\"\n",
    "\n",
    "!./maxcluster64bit -l $designable_file_path \"$cluster_dir/all_by_all_lite\" -C 2 -in -Rl \"$cluster_dir/tm_results.txt\" -Tm 0.5 > \"$cluster_dir/output.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"INFO  : Reading PDB list file '/home/shuaikes/Project/protein-evaluation-notebook/cluster/designable_paths.txt'\\nINFO  : Successfully read 0 PDBs\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08INFO  : Successfully read 6 / 6 PDBs from list file '/home/shuaikes/Project/protein-evaluation-notebook/cluster/designable_paths.txt'\\nINFO  : Successfully read 6 Chain structures\\nINFO  : Processed 0 of 15 MAXSUBs\\nINFO  : CPU time = 0.02 seconds\\nINFO  : Printing MaxSub output file /home/shuaikes/Project/protein-evaluation-notebook/cluster/tm_results.txt\\nINFO  : ======================================\\nINFO  : 3Djury (Threshold: >    20 pairs @ > 0.200)\\nINFO  : ======================================\\nINFO  : Rank     Model    Pairs       File\\nINFO  :     1 :        1      136       /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_0/sample.pdb\\nINFO  :     2 :        2      128       /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_1/sample.pdb\\nINFO  :     3 :        3      125       /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_2/sample.pdb\\nINFO  :     4 :        4      117       /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_3/sample.pdb\\nINFO  :     5 :        6      114       /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_5/sample.pdb\\nINFO  :     6 :        5       96       /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_4/sample.pdb\\nINFO  : ======================================\\nINFO  : Pairwise average linkage clustering\\nINFO  : ======================================\\nINFO  : Hierarchical Tree\\nINFO  : ======================================\\nINFO  : Node     Item 1   Item 2      Distance\\nINFO  :     0 :        4        2        0.557  /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_3/sample.pdb  /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_1/sample.pdb\\nINFO  :    -1 :        6        3        0.598  /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_5/sample.pdb  /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_2/sample.pdb\\nINFO  :    -2 :        5        1        0.648  /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_4/sample.pdb  /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_0/sample.pdb\\nINFO  :    -3 :       -1        0        0.702                                                                                                                                                                                              \\nINFO  :    -4 :       -3       -2        0.741                                                                                                                                                                                              \\nINFO  : ======================================\\nINFO  : 6 Clusters @ Threshold  0.500 (0.5)\\nINFO  : ======================================\\nINFO  : Item     Cluster\\nINFO  :     5 :        1                        /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_4/sample.pdb\\nINFO  :     1 :        2                        /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_0/sample.pdb\\nINFO  :     6 :        3                        /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_5/sample.pdb\\nINFO  :     3 :        4                        /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_2/sample.pdb\\nINFO  :     4 :        5                        /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_3/sample.pdb\\nINFO  :     2 :        6                        /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_1/sample.pdb\\nINFO  : ======================================\\nINFO  : Centroids\\nINFO  : ======================================\\nINFO  : Cluster  Centroid  Size        Spread\\nINFO  :     1 :        5        1        0.000  /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_4/sample.pdb\\nINFO  :     2 :        1        1        0.000  /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_0/sample.pdb\\nINFO  :     3 :        6        1        0.000  /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_5/sample.pdb\\nINFO  :     4 :        3        1        0.000  /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_2/sample.pdb\\nINFO  :     5 :        4        1        0.000  /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_3/sample.pdb\\nINFO  :     6 :        2        1        0.000  /home/shuaikes/Project/protein-evaluation-notebook/example_data/length_70/sample_1/sample.pdb\\nINFO  : ======================================\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = \"/home/shuaikes/Project/protein-evaluation-notebook/cluster/output.txt\"\n",
    "designable_dir = \"/home/shuaikes/Project/protein-evaluation-notebook/cluster/\"\n",
    "\n",
    "# open the output file\n",
    "with open(output_file, \"r\") as f:\n",
    "    stdout = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of decoys in cluster: 6\n"
     ]
    }
   ],
   "source": [
    "# Extract number of clusters\n",
    "match = re.search(\n",
    "    r\"INFO\\s*:\\s*(\\d+)\\s+Clusters\\s+@\\s+Threshold\\s+(\\d+\\.\\d+)\\s+\\(\\d+\\.\\d+\\)\",\n",
    "    stdout,\n",
    ")\n",
    "clusters = int(match.group(1))\n",
    "cluster_results_path = os.path.join(designable_dir, \"cluster_results.txt\")\n",
    "with open(cluster_results_path, \"w\") as f:\n",
    "    f.write(stdout)\n",
    "\n",
    "# Extract cluster centroids\n",
    "cluster_lines = stdout.split(\"\\n\")\n",
    "centroid_section = False\n",
    "for line in cluster_lines:\n",
    "    if \"Centroids\" in line:\n",
    "        centroid_section = True\n",
    "    if centroid_section:\n",
    "        match = re.search(r\"(?<=\\s)(\\/[^\\s]+\\.pdb)\", line)\n",
    "        if match is not None:\n",
    "            centroid_path = match.group(1)\n",
    "            copy_name = centroid_path.split(\"/\")[-2] + \".pdb\"\n",
    "            shutil.copy(centroid_path, os.path.join(designable_dir, copy_name))\n",
    "\n",
    "print(\"Number of decoys in cluster:\", clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
